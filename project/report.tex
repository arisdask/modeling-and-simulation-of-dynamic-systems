\documentclass[12pt]{article} % Font size 12pt
\usepackage{fontspec}
\usepackage{polyglossia}
\usepackage{geometry}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{hyperref} % For hyperlinks
\usepackage{amsmath}
\numberwithin{equation}{section}  % Reset equation counter with each section
\renewcommand{\theequation}{\arabic{section}-\arabic{equation}}
\usepackage{enumitem}

\usepackage{graphicx}      % For including images
\usepackage{caption}       % For customizing captions
\usepackage{subcaption}    % For subfigures within a figure

\usepackage{mathtools} % In preamble
\usepackage{amsfonts} % or \usepackage{amssymb}

\usepackage{comment}
\usepackage{ifthen}
\newboolean{showexamples}
\setboolean{showexamples}{true}  % or false to hide examples
% example boxes
\usepackage{tcolorbox}
\newtcolorbox{examplebox}[1]{%
  colback=white,
  colframe=gray!30,
  title={#1},
  sharp corners,
  boxrule=0.5pt,
  coltitle=black
}

\hypersetup{
    colorlinks=true,
    linkcolor=black,   % Internal links, those generated by cross-referenced elements
    filecolor=black,  % Links to local files
    urlcolor=black,    % Links to web sites
    citecolor=black,
}

\renewenvironment{examplebox}[1]{%
  \ifthenelse{\boolean{showexamples}}%
    {\begin{tcolorbox}[colback=white, colframe=gray!30, title={#1}, sharp corners, boxrule=0.5pt, coltitle=black]}%
    {\expandafter\comment}%
}{%
  \ifthenelse{\boolean{showexamples}}%
    {\end{tcolorbox}}%
    {\expandafter\endcomment}%
}

% Set fonts
\setmainfont{CMU Serif}
\newfontfamily\greekfont{CMU Serif}

% Define \greekfonttt
\newfontfamily\greekfonttt{DejaVu Sans Mono}[Script=Greek]

% Set languages
\setdefaultlanguage{greek}
\setotherlanguage{english}

% Set margins
\geometry{
    top=0cm,
    bottom=2cm,
    left=2cm,
    right=2cm
}

% modify the caption label for algorithms in the document to display "Αλγόριθμος" instead of Algorithm
\makeatletter
\renewcommand{\ALG@name}{Αλγόριθμος}
\makeatother

\setcounter{secnumdepth}{3} % Number subsubsections
\setcounter{tocdepth}{3}    % Show subsubsections in TOC

\title{\textbf{Προσομοίωση και Μοντελοποίηση \\ Δυναμικών Συστημάτων} \\ Τελική Εργασία}
\author{Αριστείδης Δασκαλόπουλος (ΑΕΜ: 10640)}
\date{\today}


\usepackage{titlesec}

% --- Sections ---
\titleformat{\section}
  {\normalfont\Large\bfseries} % Format: Large + bold
  {}                            % No label (number)
  {0pt}                         % Horizontal separation between label and title
  {}                            % Code before title
\titlespacing*{\section}        % Adjust spacing
  {0pt}                         % Left margin
  {3.5ex plus 1ex minus .2ex}   % Vertical space before
  {2.3ex plus .2ex}             % Vertical space after

% Format subsections as [X.Y] Title
\titleformat{\subsection}
  {\normalfont\large\bfseries}
  {[\thesubsection]} % Number in brackets
  {0.5em} % Space between number and title
  {}

% Format subsubsections as [X.Y.Z] Title  
\titleformat{\subsubsection}
  {\normalfont\normalsize\bfseries}
  {[\thesubsubsection]} % Number in brackets
  {0.5em} % Space between number and title
  {}

% Adjust spacing (optional)
\titlespacing*{\subsection}{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
\titlespacing*{\subsubsection}{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
  

\begin{document}
\maketitle


\renewcommand{\contentsname}{Περιεχόμενα}
\tableofcontents
\newpage
\newgeometry{
    top=2cm,
    bottom=2cm,
    left=2cm,
    right=2cm
}


\section{Θέμα 1}

% \vspace{-\topsep}
% \vspace{+2pt}
% \begin{center}
%     \textit{\textbf{Στόχος}: Εκτίμηση Άγνωστων Παραμέτρων με τις Μεθόδους Πραγματικού Χρόνου: \\Κλίσης και Lyapunov}
% \end{center}
% \vspace{-\topsep}
% \noindent\textrightarrow\ 

Το δοθέν γραμμικό σύστημα που καλούμαστε να μελετήσουμε είναι το εξής:

\vspace{-20pt}

\begin{align}\label{eq:sys_eq_1}
    \dot{x}(t) = A x(t) + B u(t),
\end{align}

\vspace{-\topsep}
% \vspace{+2pt}

\noindent όπου: 

\vspace{-\topsep}

\begin{center}
    $x(t) = \begin{bmatrix}x_1(t) & x_2(t)\end{bmatrix}^\top \in \mathbb{R}^2$ η κατάσταση του συστήματος, \hspace{0.5cm}
    $u(t) \in \mathbb{R}$ η είσοδος, \hspace{0.5cm} \\
    $A = \begin{pmatrix}
        a_{11} & a_{12} \\
        a_{21} & a_{22} \\
        \end{pmatrix}$ \hspace{0.25cm} και \hspace{0.25cm}
    $B = \begin{pmatrix}
        b_{1} \\
        b_{2} \\
        \end{pmatrix}$,
\end{center}

\vspace{-\topsep}

\noindent με τους $A$ και $B$ να θεωρούνται σταθεροί αλλά άγνωστοι/προς εκτίμηση πίνακες, 
για τα στοιχεία των οποίων γνωρίζουμε ότι ισχύουν οι παρακάτω περιορισμοί: 

\vspace{-\topsep}

\begin{center}
    \fbox{$a_{11} \in [-3, -1]$ \& $b_2 \in [1, +\infty)$}
\end{center}

% \vspace{+10pt}

Στα πλαίσια της ανάλυσής μας θεωρούνται μετρήσιμες οι καταστάσεις του συστήματος, $x_1(t)$ και $x_2(t)$, όπως και η είσοδος $u(t)$. 
Επίσης οι πραγματικές τιμές των παραμέτρων προς εκτίμηση είναι: 

\vspace{-\topsep}

\begin{table}[!ht]
    \centering
    \begin{tabular}{c c | c}
        \multicolumn{2}{c}{$A$} & $B$ \\
        $a_{11} = -2.15$ & $a_{12} = 0.25$ & $b_{1} = 0$ \\
        $a_{21} = -0.75$ & $a_{22} = -2$ & $b_{2} = 1.5$
    \end{tabular}
    % \caption{Caption}
    % \label{tab:my_label}
\end{table}

\vspace{-\topsep}
% \vspace{-10pt}

\noindent Μπορούμε εύκολα να δούμε ότι οι ιδιοτιμές του $2 \times 2$ πίνακα, $A$, είναι συζυγείς μιγαδικές και βρίσκονται στο ανοικτό αριστερό ημιεπίπεδο.

\begin{center}
    \textit{
    Στην συνέχεια θα παρουσιάσουμε έναν αλγόριθμο πραγματικού χρόνου (online) για την εκτίμηση των αγνώστων πινάκων, 
    θα μελετήσετε την ευστάθεια του συστήματος εκτίμησης που σχεδιάσαμε και, τέλος, θα εξάγουμε συμπεράσματα για την ακρίβεια των αποτελεσμάτων μας μέσω των ζητούμενων γραφικών παραστάσεων.
    }
\end{center}


\newpage

\newgeometry{
    top=2cm,
    bottom=2cm,
    left=2cm,
    right=2cm
}




\subsection{Ερώτημα Α}

Ο αλγόριθμος πραγματικού χρόνου για την εκτίμηση των $\hat{A}$ και $\hat{B}$ που θα παρουσιάσουμε στην παρακάτω ανάλυση εφαρμόζει την μέθοδο Lyapunov με προβολή\textemdash μιας και θέλουμε να κινούμαστε στον χώρο των λύσεων που ικανοποιούν τους περιορισμούς που αναφέραμε. Η δε δομή του συστήματος αναγνώρισης που επιλέγουμε να παρουσιάσουμε είναι η μεικτή (Μ) δομή (series-parallel configuration).

\subsubsection{Μαθηματική Ανάλυση Μεθόδου Lyapunov Μ δομής}

Στη Μ δομή, όπως γνωρίζουμε, χρησιμοποιούνται οι πραγματικές τιμές των \( x_1(t)\) και \( x_2(t) \) στο μοντέλο, οπότε έχουμε:
\begin{equation}\label{eq:estim_sys}
\dot{\hat{x}} = \hat{A}x + \hat{B}u + C(x - \hat{x}),
\end{equation}
όπου $\hat{A}$, $\hat{B}$: εκτιμήσεις των πινάκων $A$, $B$.

\vspace{+8pt}

\noindent\textbullet\hspace{0.2em} Το σφάλμα αναγνώρισης είναι $e = x - \hat{x}$ και παραγωγίζοντάς το ως προς τον χρόνο παίρνουμε:
\begin{equation}\label{eq:error_dot}
\dot{e} = A x + B u - \hat{A} x - \hat{B}u - Ce \xRightarrow{\substack{\tilde{A} = \hat{A} - A \\ \tilde{B} = \hat{B} - B}}
\dot{e} = - C e - \tilde{A} x - \tilde{B}u
\end{equation}


\noindent\textbullet\hspace{0.2em} Για την ανάλυσή μας ως συνάρτηση Lyapunov παίρνουμε την:
\begin{equation}\label{eq:lyapunov_b}
V = \frac{1}{2}e^{\top} e + \frac{1}{2}\text{tr}\{\tilde{A}^{\top}\tilde{A}\} + \frac{1}{2}\text{tr}\{\tilde{B}^{\top}\tilde{B}\}
\end{equation}
όπου με $\text{tr}\{\cdot\}$ συμβολίζουμε το ίχνος (trace) ενός πίνακα. Αν παραγωγίσουμε την $V$ ως προς τον χρόνο κατά μήκος της λύσης της \eqref{eq:error_dot} βρίσκουμε:
\begin{equation}\label{eq:vdot_initial_b}
\dot{V} = e^{\top} \dot{e} + \text{tr}\{\tilde{A}^{\top}\dot{\hat{A}}\} + \text{tr}\{\tilde{B}^{\top}\dot{\hat{B}}\} \overset{\eqref{eq:error_dot}}{=}
- e^{\top} C e - e^{\top} \tilde{A} x - e^{\top} \tilde{B}u + \text{tr}\{\tilde{A}^{\top}\dot{\hat{A}}\} + \text{tr}\{\tilde{B}^{\top}\dot{\hat{B}}\}.
\end{equation}
Επίσης γνωρίζουμε από τις ιδιότητες του trace ότι:
\begin{equation*}
e^{\top} \tilde{A} x = \text{tr}\{\tilde{A} x e^{\top}\} \quad\& \quad
\text{tr}\{\tilde{A}^{\top}\dot{\hat{A}}\} = \text{tr}\{\tilde{A}\dot{\hat{A}}^{\top}\}
\quad \text{(ομοίως για $B$)}
\end{equation*}
και έτσι η \eqref{eq:vdot_initial_b} γράφεται:
\begin{equation}\label{eq:vdot_intermediate_b}
\dot{V} = - e^{\top} C e + \text{tr}\{\tilde{A}\dot{\hat{A}}^{\top} + \tilde{B}\dot{\hat{B}}^{\top} - \tilde{A} x e^{\top} - \tilde{B}u e^{\top}\}.
\end{equation}



\vspace{+8pt}

\noindent\textbullet\hspace{0.2em} Για να απαλειφθούν οι όροι των οποίων το πρόσημο δεν γνωρίζουμε στην παράγωγο της Lyapunov, επιλέγουμε:
\begin{equation}\label{eq:adapt_A_B}
\dot{\hat{A}}^{\top} = x e^{\top} \quad \& \quad
\dot{\hat{B}}^{\top} = u e^{\top} \quad \Rightarrow \quad
\dot{\hat{A}} = e x^{\top} \quad \& \quad
\dot{\hat{B}} = e u^{\top},
\end{equation}
και τότε η \eqref{eq:vdot_intermediate_b} γίνεται:
\begin{equation}\label{eq:vdot_final_b}
\dot{V} = - e^{\top} C e \leq 0, \ \text{όπου ο πίνακας $C$ πρέπει να είναι θετικά (ημι)ορισμένος.}
\end{equation}

\begin{examplebox}{}
    Άρα ο αλγόριθμος με προβολή που θα αναπτύξουμε στην συνέχεια θα ακολουθεί την λύση \eqref{eq:adapt_A_B} που παρέχει η παραπάνω μέθοδος 
    (με εξαίρεση τις περιπτώσεις που φτάνουμε στο σύνορο, όπως θα εξηγήσουμε).
    Με το παραπάνω βλέπουμε επίσης πως με κατάλληλη επιλογή του πίνακα $C$ η μέθοδος (χωρίς προβολή) είναι ευσταθής. 
    (Για την σύγκληση των παραμετρικών σφαλμάτων στο μηδέν πρέπει επίσης η είσοδος να ικανοποιεί μια ΣΕΔ).
\end{examplebox}

\vspace{+5pt}



\subsubsection{Αλγόριθμος Lyapunov με Προβολή}

Για την ανάπτυξη του αλγορίθμου με προβολή ορίζουμε:
\begin{equation}\label{eq:theta_vect}
\theta = \begin{bmatrix} a_{11} & a_{12} & a_{21} & a_{22} & b_{1} & b_{2} \end{bmatrix}^\top \in \mathbb{R}^6,
\end{equation}
συνεπώς λαμβάνοντας υπόψιν την \eqref{eq:adapt_A_B} θα έχουμε (για την περίπτωση χωρίς περιορισμούς):
\begin{equation}\label{eq:theta_dot}
    \dot{\hat{\theta}} = 
    \begin{bmatrix} 
    \dot{\hat{a}}_{11} & \dot{\hat{a}}_{12} & \dot{\hat{a}}_{21} & \dot{\hat{a}}_{22} & \dot{\hat{b}}_{1} & \dot{\hat{b}}_{2} 
    \end{bmatrix}^\top 
    \overset{\eqref{eq:adapt_A_B}}{=} 
    \begin{bmatrix} 
    e_1 x_1 & e_1 x_2 & e_2 x_1 & e_2 x_2 & e_1 u & e_2 u
    \end{bmatrix}^\top, 
\end{equation}
η οποία σχέση προέκυψε αντικαθιστώντας στην \eqref{eq:adapt_A_B} τα $x = \begin{bmatrix}x_1 & x_2\end{bmatrix}^\top$ και $e = \begin{bmatrix}e_1 & e_2\end{bmatrix}^\top$.

\vspace{+5pt}

Ορίζουμε τώρα το κυρτό σύνολο $\Theta$ όλων των $\hat{\theta}$ που να ικανοποιούν τους περιορισμούς:
\begin{equation}\label{eq:Theta_def}
\Theta = \{ \hat{\theta} \in \mathbb{R}^6 : g_1(\hat{\theta}) \le 0, g_2(\hat{\theta}) \le 0, g_3(\hat{\theta}) \le 0 \},
\end{equation}
όπου τα $g_i(\hat{\theta})$, για $i  = 1, 2, 3$, ορίζονται παρακάτω έτσι, ώστε οι ανισότητες στη \eqref{eq:Theta_def} να εκφράζουν τους αρχικούς μας περιορισμούς:
\begin{center}
    $g_1(\hat{\theta}) = - \hat{a}_{11} - 3$, \hspace{0.5cm}
    $g_2(\hat{\theta}) = \hat{a}_{11} + 1$, \hspace{0.5cm}
    $g_3(\hat{\theta}) = - \hat{b}_{2} + 1$. 
\end{center}

\begin{examplebox}{Σχόλιο}
    Ο διανυσματικός ορισμός του $g(\hat{\theta})$ μπορεί να διατυπωθεί ως:
    $$
    g(\hat{\theta}) = \begin{bmatrix}
        g_1 & g_2 & g_3
    \end{bmatrix}^\top \in \mathbb{R}^3.
    $$
    Τότε στην έκφραση των περιορισμών στην \eqref{eq:Theta_def} θα είχαμε την διανυσματική ανισότητα: $g(\hat{\theta}) < 0_{3 \times 1}$. 
    Αυτή η μορφή είναι μαθηματικά ισοδύναμη με την ανάλυση καθενός από τους επιμέρους όρους/συνιστώσες $g_i < 0$, για $i = 1, 2, 3$. 
\end{examplebox}

\vspace{+5pt}

Για την ανάπτυξη του αλγορίθμου με προβολή, εκκινούμε από ένα αρχικό σημείο $\hat{\theta}(0) = \hat{\theta}_0$ το οποίο βρίσκεται στο εσωτερικό του συνόλου $\Theta$, και ακολουθούμε τη δυναμική που υπαγορεύεται από τη Σχέση~\eqref{eq:theta_dot} (που δεν λαμβάνει υπόψιν τους περιορισμούς). 
Όταν η τροχιά φτάσει στο σύνορο του $\Theta$\textemdash δηλαδή όταν για κάποιο $i \in {1, 2, 3}$ ισχύει $g_i(\hat{\theta}) = 0$\textemdash εξετάζεται αν το $\hat{\theta}$ τείνει να κινηθεί εκτός του επιτρεπτού συνόλου $\Theta$, και έχουμε περιπτώσεις:
\begin{itemize}[noitemsep, nolistsep]
    \item Εάν αυτό δεν συμβαίνει, συνεχίζουμε να εφαρμόζουμε την ίδια δυναμική. 
    \item Σε αντίθετη περίπτωση, \textit{\textbf{προστίθεται κατάλληλος όρος}}, ο οποίος εξαναγκάζει την κίνηση του $\hat{\theta}$ προς το εσωτερικό του $\Theta$ ή κατά μήκος του συνόρου του.
\end{itemize}

Σύμφωνα με τα παραπάνω προκύπτει ο αλγόριθμος με προβολή ως:
\begin{equation}\label{eq:theta_dot_proj}
\dot{\hat{\theta}} = 
\begin{cases} 
    \Gamma \begin{bmatrix} e_1 x_1 \\ e_1 x_2 \\ e_2 x_1 \\ e_2 x_2 \\ e_1 u \\ e_2 u \end{bmatrix}, 
    & \begin{split}
        \text{αν } \hat{\theta} \in \Theta_{in} \text{ \textit{ή αν} } \\
        \hat{\theta} \in \Theta_b \quad  \& \quad \dot{\hat{\theta}}^{\top}_{\eqref{eq:theta_dot}} \cdot \nabla g \le 0_{3 \times 1}
    \end{split} \\
    \Gamma \begin{bmatrix} e_1 x_1 \\ e_1 x_2 \\ e_2 x_1 \\ e_2 x_2 \\ e_1 u \\ e_2 u \end{bmatrix} - \Gamma \frac{\nabla g \nabla g^{\top}}{\nabla g^{\top} \Gamma \nabla g} \Gamma \begin{bmatrix} e_1 x_1 \\ e_1 x_2 \\ e_2 x_1 \\ e_2 x_2 \\ e_1 u \\ e_2 u \end{bmatrix}, & \text{διαφορετικά}
\end{cases}
\end{equation}
όπου \(\Theta_{in}\) είναι το εσωτερικό και \(\Theta_b\) το σύνορο του $\Theta$. Στην \eqref{eq:theta_dot_proj} πρέπει \(\hat{\theta}(0) \in \Theta\). 

Για την \eqref{eq:theta_dot_proj} ισχύουν τα εξής:
\begin{itemize}[noitemsep, nolistsep]
    \item Ο πίνακας $\Gamma = \begin{bmatrix}
        \gamma_1 & 0        & \cdots & 0 \\
        0        & \gamma_2 & \cdots & 0 \\
        \vdots    & \vdots   & \ddots & \vdots \\
        0        & 0        & \cdots & \gamma_6
    \end{bmatrix} \in \mathbb{R}^{6 \times 6}$
    περιλαμβάνει όλες τις μεταβλητές $\gamma_i > 0$ (learning rate) με τις οποίες θα πολλαπλασιαστεί καθεμία συνιστώσα του διανύσματος $\dot{\hat{\theta}}$.

    \item Όταν το $g$ εκφράζει διανυσματικά όλους τους περιορισμούς ισχύει: 
        $$\nabla g = \begin{bmatrix}
            \nabla g_1 & \nabla g_2 & \nabla g_3
        \end{bmatrix}\in \mathbb{R}^{6 \times 3},$$
        όπου: 
        \begin{equation}\label{eq:grad_g}
            \nabla g_1 = \begin{bmatrix}
                -1 & 0 & 0 & 0 & 0 & 0
            \end{bmatrix}^{\top}, \quad 
            \nabla g_2 = \begin{bmatrix}
                1 & 0 & 0 & 0 & 0 & 0
            \end{bmatrix}^{\top}, \quad 
            \nabla g_3 = \begin{bmatrix}
                0 & 0 & 0 & 0 & 0 & -1
            \end{bmatrix}^{\top}
        \end{equation}

        \item Ο λόγος $\frac{\nabla g \nabla g^\top}{\nabla g^\top \Gamma \nabla g} \in \mathbb{R}^{6 \times 6}$ εκφράζει τον μηχανισμό με τον οποίο προβάλλεται το διάνυσμα $\hat{\theta}$ εντός του επιτρεπτού χώρου $\Theta$, όταν διαπιστώνεται ότι τείνει να κινηθεί εκτός αυτού\textemdash δηλαδή, όταν ο πρώτος κλάδος είτε οδηγεί σε τιμή εκτός του $\Theta$, είτε δίνει σημείο στο σύνορό του, αλλά με παράγωγο $\dot{\hat{\theta}}$ που έχει φορά προς το εξωτερικό του συνόλου.

        Για τον δε υπολογισμό του λόγου αυτού η μαθηματική ισοδυναμία ώστε να οδηγεί σε προβολή στο $\Theta$ είναι:  $\nabla g (\nabla g^\top \Gamma \nabla g)^{-1} \nabla g^\top$.

        \begin{examplebox}{Παρατήρηση}
            Για οποιοδήποτε διαγώνιο πίνακα $\Gamma$ κατόπιν αντικατάστασης και εύρεσης του $\nabla g^\top \Gamma \nabla g$, παρατηρούμε ότι αυτός είναι ιδιάζον (μη αντιστρέψιμος/με ορίζουσα μηδέν). 
            Αυτό συμβαίνει επειδή οι περιορισμοί που εκφράζουν οι συναρτήσεις $g_1$ και $g_2$ αναφέρονται στην ίδια παράμετρο $a_{11}$ και δεν γίνεται και οι δύο ταυτόχρονα να είναι $\ge 0$.
            Άρα η έκφραση του λόγου ως αντίστροφος πίνακας, όπως δείξαμε προηγουμένως, δεν μπορεί να εφαρμοστεί στην περίπτωσή μας. 
        \end{examplebox} 
        
\end{itemize}


Για την επίλυση του προβλήματος, στην περίπτωση όπου πρέπει να πάρουμε τον δεύτερο κλάδο της \eqref{eq:theta_dot_proj}, θα προβάλουμε την λύση λαμβάνοντας μόνο τους ενεργούς περιορισμούς. Ένας τρόπος να το κάνουμε αυτό είναι ο παρακάτω:

Τροποποιούμε τον αλγόριθμο που παρουσιάζει η \eqref{eq:theta_dot_proj}\textemdash και συγκεκριμένα τον δεύτερο κλάδο που κάνει την προβολή\textemdash ώστε να χρησιμοποιούμε άθροισμα επί των περιορισμών.
Επομένως, στον τροποποιημένο αλγόριθμο, ο όρος προβολής ανανεώνεται ως:

\begin{equation}
    \dot{\hat{\theta}} = 
    \Gamma \begin{bmatrix} e_1 x_1 \\ e_1 x_2 \\ e_2 x_1 \\ e_2 x_2 \\ e_1 u \\ e_2 u \end{bmatrix} - 
    \sum_{i \in \mathcal{A}} \Gamma \frac{\nabla g_i \nabla g_i^{\top}}{\nabla g_i^{\top} \Gamma \nabla g_i} \Gamma \begin{bmatrix} e_1 x_1 \\ e_1 x_2 \\ e_2 x_1 \\ e_2 x_2 \\ e_1 u \\ e_2 u \end{bmatrix},
\end{equation}

ή για απλότητα:

\begin{equation}\label{eq:update_theta}
    \dot{\hat{\theta}}_{new} = 
    \Gamma \dot{\hat{\theta}}_{current} - 
    \sum_{i \in \mathcal{A}} \Gamma \frac{\nabla g_i \nabla g_i^{\top}}{\nabla g_i^{\top} \Gamma \nabla g_i} \Gamma \dot{\hat{\theta}}_{current},
\end{equation}

όπου \(\mathcal{A}\) είναι το σύνολο των \textit{ενεργών περιορισμών}\textemdash δηλαδή, οι δείκτες \(i\) για τους οποίους είτε \(g_i(\hat{\theta}) > 0\), είτε \(g_i(\hat{\theta}) = 0 \ \& \ \dot{\hat{\theta}}_{\eqref{eq:theta_dot}} \cdot \nabla g_i > 0\). 

\begin{examplebox}{}
    Με \(\dot{\hat{\theta}}_{\eqref{eq:theta_dot}}\) συμβολίζουμε την \textit{χωρίς περιορισμούς} επόμενη ενημέρωση του διανύσματος $\dot{\hat{\theta}}_{current}$ (ακολουθώντας την μέθοδο Lyapunov για την Μ δομή). 
\end{examplebox}


Το άθροισμα επί των ενεργών περιορισμών εμφανίζεται επειδή, όταν πολλαπλοί περιορισμοί είναι ενεργοί (παρατηρώντας τους περιορισμούς μπορούμε να έχουμε max δύο ενεργούς περιορισμούς: $g_1$ με $g_3$ ή $g_2$ με $g_3$), η ενημέρωση πρέπει να προβληθεί ως προς όλους τους ενεργούς περιορισμούς.

Ο όρος $\Gamma \frac{\nabla g_i \nabla g_i^{\top}}{\nabla g_i^{\top} \Gamma \nabla g_i} \Gamma \dot{\hat{\theta}}$ προβάλλει την ενημέρωση \(\dot{\hat{\theta}}\) στην κάθετη κατεύθυνση της \(i\)-οστής επιφάνειας περιορισμού, $g_i(\hat{\theta}) = 0$. 
Η αφαίρεση του αποτελέσματος της προβολής αφαιρεί τη συνιστώσα του \(\dot{\hat{\theta}}\) που θα παραβίαζε το \( g_i(\hat{\theta}) \leq 0 \). 
Όταν πολλαπλοί περιορισμοί είναι ενεργοί, αθροίζουμε αυτές τις προβολές για να αφαιρέσουμε τις συνιστώσες κατά μήκος όλων των σχετικών κάθετων κατευθύνσεων,
διασφαλίζοντας ότι η ενημέρωση του \(\dot{\hat{\theta}}\) παραμένει στο σύνορο $\Theta_b$.

Ο λόγος για τον οποίο το άθροισμα στην \eqref{eq:update_theta} είναι μαθηματικά σωστό είναι επειδή σε περίπτωση που έχουμε πολλαπλούς ενεργούς περιορισμούς, τότε όπως εξηγήσαμε αυτό σημαίνει ότι $\mathcal{A} = \{1, 3\} \ \text{ή} \ \{2, 3\}$.
Άρα, επειδή από τις \eqref{eq:grad_g} έχουμε $\nabla g_1^{\top} \cdot \nabla g_3 = 0$ και $\nabla g_2^{\top} \cdot \nabla g_3 = 0$, 
επομένως οι προβολές ως προς αυτά τα ζεύγη είναι μεταξύ τους ορθογώνιες και έπεται πως μπορούν να υπολογιστούν και να αφαιρεθούν ανεξάρτητα οι συνιστώσες που δίνουν. 
Εναλλακτικά, θα έπρεπε να σχηματίζουμε κάθε φορά ένα διάνυσμα $g'$ με όλους τους ενεργούς περιορισμούς.




\vspace{+10pt}

\begin{center}
    \textit{Έχοντας πλέον ολοκληρώσει την θεωρητική ανάλυση του προβλήματος μπορούμε να συνεχίσουμε με την συνοπτική ανάλυση του τρόπου προσομοίωσης/επίλυσης του προβλήματος στο MATLAB.}
\end{center}

\newpage

\subsubsection{Προσομοίωση στο MATLAB}

Συνοψίζοντας την ανάλυση της προηγούμενης ενότητας, για την εύρεση των προς εκτίμηση παραμέτρων, έχουμε καταλήξει στο εξής σύστημα προς επίλυση:

\noindent\textbullet\hspace{0.2em} Η πρώτη διαφορική εξίσωση που θέλουμε να λύσουμε είναι αυτή του πραγματικού συστήματος, 
καθώς για κάθε χρονική στιγμή πρέπει να γνωρίζουμε την $x(t)$ (η μέθοδος είναι πραγματικού χρόνου επομένως λύνουμε με \textit{ode45} αυτήν την διαφορική, ταυτόχρονα με όλες τις υπόλοιπες):
\begin{equation}
    \dot{x}(t) = A_{\text{true}} x(t) + B_{\text{true}} u(t),
\end{equation}
όπου \( x(t) \in \mathbb{R}^2 \) είναι το διάνυσμα κατάστασης και \( u(t) \in \mathbb{R} \) είναι ένα γνωστό σήμα εισόδου της επιλογής μας (θα αναφερθούμε στην επιλογή του παρακάτω).  

\noindent\textbullet\hspace{0.2em} Η δεύτερη διαφορική αναφέρεται στο σύστημα αναγνώρισης. Οι πίνακες \( A_{\text{true}} = A \in \mathbb{R}^{2 \times 2} \) και \( B_{\text{true}} = B \in \mathbb{R}^{2 \times 1} \) για το πάνω σύστημα θεωρούνται γνωστοί, 
όμως θα πρέπει να εκτιμηθούν από το σύστημα αναγνώρισης το οποίο ορίστηκε στην προηγούμενη ανάλυση με την παρακάτω μεικτή δομή:
\begin{equation}
    \dot{\hat{x}}(t) = A_{\text{hat}} x(t) + B_{\text{hat}} u(t) + C \left( x(t) - \hat{x}(t) \right),
\end{equation}
όπου:
\[
\hat{A} = A_{\text{hat}} = 
\begin{bmatrix}
\hat\theta_1 & \hat\theta_2 \\
\hat\theta_3 & \hat\theta_4
\end{bmatrix}, \quad
\hat{B} = B_{\text{hat}} = 
\begin{bmatrix}
\hat\theta_5 \\
\hat\theta_6
\end{bmatrix}, \quad
e(t) = x(t) - \hat{x}(t), \quad 
C = \theta_{m} \cdot I_2,
\]
με το $\theta_{m}$ να πρέπει να είναι θετικός αριθμός της επιλογής μας, ώστε να ικανοποιείται η \eqref{eq:vdot_final_b}.

\noindent\textbullet\hspace{0.2em} Τέλος το σύστημά μας πρέπει να περιλαμβάνει τον νόμο ενημέρωσης παραμέτρων (με περιορισμούς).
Ο αντίστοιχος νόμος χωρίς περιορισμούς δίνεται από την \eqref{eq:theta_dot}, 
και κλιμακώνεται από έναν θετικά ορισμένο διαγώνιο πίνακα \( \Gamma = \mathrm{diag}(\gamma_1, \ldots, \gamma_6) \).
Για την δε επιβολή περιορισμών στις παραμέτρους, εφαρμόζεται η μέθοδος προβολής της \eqref{eq:update_theta}.


Άρα, το πλήρες σύστημα που θα δώσουμε στην \textit{ode45} για επίλυση είναι το εξής:
\begin{equation}
\frac{d}{dt}
\begin{bmatrix}
x(t) \\
\hat{x}(t) \\
\theta(t)
\end{bmatrix}
=
\begin{bmatrix}
A_{\text{true}} x(t) + B_{\text{true}} u(t) \\
A_{\text{hat}} x(t) + B_{\text{hat}} u(t) + C (x(t) - \hat{x}(t)) \\
\text{Proj}\left( \hat\theta_{\text{current}}, \Gamma \dot{\hat\theta}_{\text{current}} \right)
\end{bmatrix},
\end{equation}
με κατάλληλες αρχικές τιμές για τα $x_0$, $\hat{x}_0$ και $\hat\theta_0$.

\begin{examplebox}{Σχόλιο}
    Η συνάρτηση προβολής $\text{Proj}\left( \hat\theta_{\text{current}}, \Gamma \dot{\hat\theta}_{\text{current}}  \right)$ 
    παίρνει ως όρισμα και το $\hat\theta_{\text{current}}$ για να ελέγξει το εσωτερικό γενόμενο αυτού με τις παραγώγους των συναρτήσεων περιορισμών, 
    \eqref{eq:grad_g}\textemdash μιας και με βάση το πρόσημο του αποτελέσματος βρίσκει αν και ποιοι εκ των περιορισμών είναι ενεργοί ώστε να κάνει την αντίστοιχη προβολή. 
\end{examplebox}

Στο αρχείο \textit{src/constrainedSystemDynamics.m} έχει εκφραστεί το παραπάνω σύστημα, 
το οποίο λύνεται (με \textit{ode45}) στο εκτελέσιμο script: \underline{\textit{mainPart1a.m}} που αντιστοιχεί στο Ερώτημα α του Θέματος 1.

\begin{center}
    \textit{Στην συνέχεια παραθέτουμε τις ζητούμενες γραφικές παραστάσεις και εξάγουμε σχετικά συμπεράσματα.}
\end{center}

\subsubsection{Αποτελέσματα MATLAB και Συμπεράσματα}
TODO:\\
 - έλεγχος ευστάθειας \\
 - επιλογη εισόδου \\
 - Βάλε τα πλοτ που έβγαλες \\
 - πες συμπεράσματα \\



\newpage

\subsection{Ερώτημα Β}

Στην ανάλυση του προβλήματός μας ως τώρα υποθέσαμε την \textit{\textbf{πλήρη γνώση της δομής του συστήματος}} που μελετάμε 
και με βάση αυτήν σχεδιάσαμε έναν τρόπο εκτίμησης των άγνωστων παραμέτρων του (λαμβάνοντας υπόψιν τους δοθέντες περιορισμούς). 
Σε πρακτικές εφαρμογές όμως αυτό είναι ανεφάρμοστο, μιας και πάντα υπάρχουν άγνωστες μη γραμμικότητες που δεν μοντελοποιούνται. 

Γι' αυτόν τον λόγο, σε αυτό το ερώτημα θα εισάγουμε στο σύστημα \textbf{σφάλμα πόλωσης} $\omega \in \mathbb{R}^2$ 
που να ικανοποιεί $||\omega(t)|| \le \bar{\omega}, \forall t \ge 0$, για κάποια άγνωστη σταθερά $\bar{\omega} > 0$.

\subsubsection{Γραμμικά Παραμετροποιημένη Μορφή}

\textit{Πριν το κάνουμε αυτό}, θα φέρουμε το σύστημα \eqref{eq:sys_eq_1} σε γραμμικά παραμετροποιημένη μορφή, ακολουθώντας τα παρακάτω βήματα:

\noindent\textbullet\hspace{0.2em} Αρχικά, ορίζουμε ένα διάνυσμα $\theta^*$ (όπως κάναμε και στο Ερώτημα Α) στο οποίο συγκεντρώνουμε όλες τις προς εκτίμηση παραμέτρους της \eqref{eq:sys_eq_1}:
\vspace{-\topsep}
\vspace{+2pt}
\begin{equation}
   \theta^* = \begin{bmatrix} a_{11} & a_{12} & a_{21} & a_{22} & b_{1} & b_{2} \end{bmatrix}^\top \in \mathbb{R}^6. 
\end{equation}

\noindent Επίσης, ορίζουμε πίνακα $\Delta \in \mathbb{R}^{2 \times 6}$ που περιλαμβάνει όλα τα σήματα εισόδου-εξόδου, ως εξής:
\begin{equation}
\Delta = \begin{bmatrix}
    x_1 & x_2 & 0   & 0   & u & 0 \\
    0   & 0   & x_1 & x_2 & 0 & u
\end{bmatrix}.
\end{equation}

\noindent Σύμφωνα με τα παραπάνω το αρχικό μας σύστημα μπορεί να γραφεί στην μορφή:
\vspace{-\topsep}
\vspace{+2pt}
\begin{equation}\label{eq:sys_linear_param}
    \dot{x} = \Delta \cdot \theta^{*}
\end{equation}

\vspace{-\topsep}
\vspace{+3pt}

\noindent Η παραπάνω μορφή εκφράζει την παράγωγο του διανύσματος $x(t) = \begin{bmatrix} x_1(t) & x_2(t)  \end{bmatrix}^{\top}$ ως το γινόμενο του διανύσματος των παραμέτρων $\theta^{*}$ με τον πίνακα όλων των (γνωστών) σημάτων, $\Delta$.

\vspace{+5pt}

\noindent\textbullet\hspace{0.2em} 
Το σύστημα έχει δύο εξόδους, τις $x_1$ και $x_2$, συνεπώς ορίζουμε $y(t) = x(t)$. 
Για να φέρουμε το σύστημα \eqref{eq:sys_linear_param} στην μορφή $y = \Phi \theta^{*} $\textemdash 
με το $\Phi$ εδώ να είναι πίνακας στο $\mathbb{R}^{2 \times 6}$\textemdash 
πρέπει να απαλλαχθούμε από την παράγωγο $\dot{x}(t)$.
Για να πετύχουμε το ζητούμενο, φιλτράρουμε και τα δύο μέλη της \eqref{eq:sys_linear_param} (κάθε συνιστώσα ξεχωριστά) με κατάλληλης τάξης ευσταθές φίλτρο, $\frac{1}{\Lambda(s)}$.
Για απλότητα και για τις δύο συνιστώσες, μπορούμε να επιλέξουμε ένα φίλτρο πρώτης τάξης, μορφής:
\vspace{-\topsep}
\vspace{+3pt}
\begin{equation}\label{eq:filter}
\frac{1}{\Lambda(s)}, \quad \text{με }\Lambda(s) = s + \lambda,\  \lambda \in \mathbb{R},
\end{equation}
με την ρίζα του πολυωνύμου αυτού να κυμαίνεται στο αριστερό ανοιχτό ημιεπίπεδο, δηλαδή $\lambda > 0$, για να έχουμε ευστάθεια.
Υπενθυμίζουμε ότι και το αρχικό μας σύστημα είναι ευσταθές, μίας και\textemdash όπως αναφέρθηκε και στην εισαγωγική ανάλυση\textemdash 
οι ιδιοτιμές του πίνακα $A$, της \eqref{eq:sys_eq_1}, βρίσκονται στο ανοικτό αριστερό ημιεπίπεδο.


\vspace{+5pt}

\noindent\textbullet\hspace{0.2em} Από την \eqref{eq:sys_linear_param}, παίρνουμε (περνώντας στο πεδίο του Laplace):
\vspace{-\topsep}
\vspace{+3pt}
\begin{equation}\label{eq:sys_param_filter}
  \begin{aligned}
    \left.
      \begin{aligned}
        s X_1 &= a_{11} X_1 + a_{12} X_2 + b_1 U \\
        s X_2 &= a_{21} X_1 + a_{22} X_2 + b_2 U
      \end{aligned}
    \right\}
    &\Rightarrow
    \left.
      \begin{aligned}
        (s + \lambda_1) X_1 &= (a_{11} + \lambda_1) X_1 + a_{12} X_2 + b_1 U \\
        (s + \lambda_2) X_2 &= a_{21} X_1 + (a_{22} + \lambda_2) X_2 + b_2 U
      \end{aligned}
    \right\} \\
    &\Rightarrow
    \left.
      \begin{aligned}
        X_1 &= \frac{a_{11} + \lambda_1}{s + \lambda_1} X_1 + \frac{a_{12}}{s + \lambda_1} X_2 + \frac{b_1}{s + \lambda_1} U \\
        X_2 &= \frac{a_{21}}{s + \lambda_2} X_1 + \frac{a_{22} + \lambda_2}{s + \lambda_2} X_2 + \frac{b_2}{s + \lambda_2} U 
      \end{aligned}
    \right\}
  \end{aligned}
\end{equation}
και όπως βλέπουμε τώρα, καταφέραμε να διώξουμε την παράγωγο και έχουμε απλώς την $x$.

\begin{examplebox}{Σχόλιο}
    Όπως παρατηρούμε, στην \eqref{eq:sys_param_filter} δεν χρειάζεται για κάθε συνιστώσα να έχουμε το ίδιο ακριβώς φίλτρο. 
    Παρόλα αυτά, για απλότητα (και συμμετρία μεταξύ των συνιστωσών) στην ανάλυσης στο MATLAB θα έχουμε $\lambda_1 = \lambda_2 = \lambda$.
\end{examplebox}

Από την \eqref{eq:sys_param_filter} έχουμε ισοδύναμα:
\vspace{-\topsep}
\vspace{+3pt}
\begin{equation}\label{eq:sys_param_filter_2}
\begin{aligned}
        \eqref{eq:sys_param_filter} &\Rightarrow
        \begin{bmatrix}
            X_1 \\ X_2
        \end{bmatrix} = 
        \begin{bmatrix}
            \frac{X_1}{s + \lambda_1}  & \frac{X_2}{s + \lambda_1}  & 0 & 0 & \frac{U}{s + \lambda_1}  & 0 \\ 
            0 & 0 & \frac{X_1}{s + \lambda_2}  & \frac{X_2}{s + \lambda_2}  & 0 & \frac{U}{s + \lambda_2} \\ 
        \end{bmatrix}
        \begin{bmatrix}
            a_{11} + \lambda_1 \\ a_{12} \\ a_{21} \\ a_{22} + \lambda_2 \\ b_1 \\ b_2
        \end{bmatrix} \\
        &\overset{ILT}{\Rightarrow}
        y = \begin{bmatrix}
            x_1 \\ x_2
        \end{bmatrix} = 
        \begin{bmatrix}
            x^{[\lambda_1]}_1  & x^{[\lambda_1]}_2  & 0 & 0 & u^{[\lambda_1]}  & 0 \\ 
            0 & 0 & x^{[\lambda_2]}_1  & x^{[\lambda_2]}_2  & 0 & u^{[\lambda_2]} \\ 
        \end{bmatrix}
        \begin{bmatrix}
            a_{11} + \lambda_1 \\ a_{12} \\ a_{21} \\ a_{22} + \lambda_2 \\ b_1 \\ b_2
        \end{bmatrix}
\end{aligned}
\end{equation}
και επιστρέφοντας στο πεδίο του χρόνου βλέπουμε ότι έχουμε φέρει το σύστημα \eqref{eq:sys_eq_1} σε μορφή $y = \Phi \theta_{\lambda}^{*} $\textemdash 
όπου όλα τα στοιχεία του πίνακα $\Phi \in \mathbb{R}^{2 \times 6}$ είναι γνωστά (μπορούν να υπολογιστούν - αποτελούν τις εξόδους των φίλτρων).

\vspace{+5pt}

\begin{examplebox}{Παρατηρήσεις}
    \begin{enumerate}
        \item Στον τύπο \eqref{eq:sys_param_filter_2}, ο συμβολισμός $x^{[\lambda_j]}_i(t) \in \mathbb{R}, \ i,j \in \{1, 2\},$ χρησιμοποιείται όταν περνάμε με τον αντίστροφο μετασχηματισμό Laplace (ILT) στο πεδίο του χρόνου και αναφέρεται στο σήμα που προκύπτει όταν περάσουμε το αρχικό σήμα $x_i(t)$ από το φίλτρο πρώτης τάξης (της μορφής της \eqref{eq:filter}, για $\lambda = \lambda_j$).

        \item Ο τύπος της \eqref{eq:sys_param_filter_2} μπορεί να γραφεί ξεχωριστά για καθεμία από τις συνιστώσες της $y(t) = \begin{bmatrix}
            y_1(t) & y_2(t)
        \end{bmatrix}^{\top}$ 
        οι οποίες είναι σε γραμμικά παραμετροποιημένη μορφή, μιας και:
        \begin{equation*}
            y_1 = x_1 = 
        \begin{bmatrix}
            x^{[\lambda_1]}_1  & x^{[\lambda_1]}_2  & 0 & 0 & u^{[\lambda_1]}  & 0
        \end{bmatrix}
        \begin{bmatrix}
            a_{11} + \lambda_1 \\ a_{12} \\ a_{21} \\ a_{22} + \lambda_2 \\ b_1 \\ b_2
        \end{bmatrix} = 
        \phi_1 ^{\top} \cdot \theta_{\lambda}^{*} = \theta_{\lambda}^{*\top} \cdot \phi_1 ,
        \end{equation*} 
        και αντίστοιχα για την $y_2(t)$.
    \end{enumerate}
\end{examplebox}

Συνοψίζοντας, φέραμε το σύστημα \eqref{eq:sys_eq_1} στην (γραμμικά παραμετροποιημένη) μορφή $y = \Phi \theta_{\lambda}^{*}$ \eqref{eq:sys_param_filter_2}. 
Σε αυτήν, όπως εξηγήσαμε όλα τα μεγέθη είναι γνωστά και μετρήσιμα/υπολογίσιμα εκτός από το διάνυσμα $\theta_\lambda$\textemdash 
οπότε μπορούμε να προχωρήσουμε την ανάλυσή μας.




\newpage 

\subsubsection{Εισαγωγή Σφάλματος Πόλωσης στο Σύστημα}
Για να καταλήξουμε στην \eqref{eq:sys_param_filter_2} θεωρήσαμε γνωστή, μέσω της \eqref{eq:sys_eq_1}, την δομή του συστήματος που μελετάμε.
Όπως αναφέραμε όμως, σε πρακτικές εφαρμογές πάντα υπάρχουν άγνωστες μη-γραμμικότητες. 
Έτσι, ακόμα και αν γνωρίζαμε το προς εκτίμηση \(\theta^*\), η έξοδος του συστήματος στην πράξη δεν θα περιγράφονταν από την \eqref{eq:sys_param_filter_2} αλλά από την:
\begin{equation}\label{eq:system_polosi}
    y = \Phi \theta_{\lambda}^{*} + \omega, 
\end{equation}
στην οποία, ο όρος \(\omega\) μπορεί να θεωρηθεί ως το σφάλμα προσέγγισης της εξόδου \(y\) του πραγματικού συστήματος από το $\Phi \theta_{\lambda}^{*}$ και στην ανάλυση που κάνουμε για αυτό ισχύει ότι: $||\omega(t)|| \le \bar{\omega}, \forall t \ge 0$, για κάποια άγνωστη σταθερά $\bar{\omega} > 0$.

Για να λύσουμε το πρόβλημα μπορούμε να χρησιμοποιήσουμε την διακοπτική $\sigma$-τροποποίηση η οποία, σύμφωνα με την θεωρία, 
εξασφαλίζει τόσο ότι δεν θα έχουμε παραμετρική ολίσθηση όσο και σύγκλιση του σφάλματος εξόδου στο $0$ (θεωρητικά).
Εφόσον έχουμε ήδη φέρει το σύστημα στην μορφή \eqref{eq:sys_param_filter_2}, στην συνέχεια θα σχεδιάσουμε/εφαρμόσουμε την μέθοδο κλίση με συνεχή διακοπτική $\sigma$-τροποποίηση για την εύρεση των παραμέτρων $\theta_{\lambda}^{*}$.

Το σύστημα που χρειάζεται να λύσουμε για την εύρεση των παραμέτρων $\hat\theta_{\lambda}^{*}$, αν δεν είχαμε περιορισμούς για τις επιτρεπτές τιμές αυτών, είναι το εξής:
\begin{align}\label{eq:system_biased_omega}
    y &= \Phi \theta_{\lambda}^{*} + \omega, \quad |\theta_{\lambda}^{*}| \leq M \notag \\
    \hat{y} &= \Phi\hat{\theta}_{\lambda}^{*}  \notag\\
    \dot{\hat{\theta}}_{\lambda}^{*} &= -\sigma_\delta \Gamma \hat{\theta}_{\lambda}^{*} -\Gamma \nabla K(\hat{\theta}_{\lambda}^{*}) \\
    \sigma_\delta &= 
    \begin{cases}
        0, & \text{αν } |\hat{\theta}_{\lambda}^{*}| < M \\
        \sigma \left( \frac{|\hat{\theta}_{\lambda}^{*}|}{M} - 1 \right), & \text{αν } M \leq |\hat{\theta}_{\lambda}^{*}| \leq 2M \\
        \sigma, & \text{αν } |\hat{\theta}_{\lambda}^{*}| > 2M
    \end{cases} \notag,
\end{align}
όπου:
\begin{itemize}[noitemsep, nolistsep]
    \item Το $K(\hat{\theta}_{\lambda}^{*})$ είναι η συνάρτηση κόστους που θέλουμε να ελαχιστοποιήσουμε για $\hat{\theta}_{\lambda}^{*} \in \Theta$. Ως συνάρτηση κόστους επιλέγουμε την $K(\hat{\theta}_{\lambda}^{*}) = \frac{||e||^2}{2} = \frac{||y - \Phi\hat{\theta}_{\lambda}^{*}||^2}{2}$.
    Παραγωγίζοντάς την παίρνουμε $\nabla K(\hat{\theta}_{\lambda}^{*}) = -\Phi^{\top} e$.
    \item Το $M >0$ είναι γνωστή σταθερά την οποία πρέπει να θέσουμε σε κατάλληλη τιμή μέσω trial and error για να ικανοποιεί την: $|\theta_{\lambda}^{*}| \leq M$ (άρα πρέπει να οριστεί ίση με έναν αρκούντως μεγάλο θετικό αριθμό). 
    \item Το $\sigma >0$ είναι ο συντελεστής της $\sigma$-τροποποίησης. Θα μπορούσαμε να ορίζουμε διαφορετικό $\sigma$ για κάθε μία εκ των παραμέτρων προς εκτίμηση, $\hat{\theta}_i$, όμως για απλότητα διατηρούμε ίδια τιμή σε όλους. 
\end{itemize}

Για να αξιοποιεί ο αλγόριθμος πραγματικού χρόνου που σχεδιάζουμε την πληροφορία ότι $\hat{\theta}_{\lambda}^{*} \in \Theta$, 
στην ενημέρωση του $\dot{\hat{\theta}}_{\lambda}^{*}$ που παραθέσαμε στο παραπάνω σύστημα της \eqref{eq:system_biased_omega} 
θα εφαρμόζουμε προβολή στο σύνορο $\Theta_b$ μέσω της σχέσης \eqref{eq:update_theta} που αναπτύξαμε για τις συνθήκες περιορισμού του προβλήματος. 
Έτσι, μπορούμε να εγγυηθούμε ότι το $\hat{\theta}_{\lambda}^{*}$ δεν θα βγει ποτέ εκτός του συνόλου $\Theta$.

\begin{examplebox}{Παρατήρηση}
    Ο αλγόριθμος που θέλουμε να σχεδιάσουμε είναι πραγματικού χρόνου. 
    Επομένως πρέπει στο σύστημα εξισώσεων της \eqref{eq:system_biased_omega} να συμπεριλάβουμε και τον μηχανισμό με τον οποίο βρίσκουμε τις μη μηδενικές συνιστώσες του πίνακα $\Phi$, για κάθε δεδομένη χρονική στιγμή.
    Από την \eqref{eq:sys_param_filter_2} βλέπουμε ότι για τα μη μηδενικά στοιχεία του πίνακα $\Phi$ 
    (και για $\lambda_1 = \lambda_2 = \lambda$) ισχύει:
    \begin{align*}
        \Phi_{11} &= \frac{X_1}{s + \lambda} \xRightarrow{ILT} \dot\Phi_{11}(t) = x_1(t) - \lambda \Phi_{11}(t), \quad \Phi_{11}(t) = \Phi_{23}(t)\  (\text{για κοινό φίλτρο $\lambda$}), \\
        \Phi_{12} &= \frac{X_2}{s + \lambda} \xRightarrow{ILT} \dot\Phi_{12}(t) = x_2(t) - \lambda \Phi_{12}(t), \quad \Phi_{12}(t) = \Phi_{24}(t)\  (-//-), \\
        \Phi_{15} &= \frac{U}{s + \lambda} \xRightarrow{ILT} \dot\Phi_{15}(t) = u(t) - \lambda \Phi_{15}(t), \quad \Phi_{15}(t) = \Phi_{26}(t)\  (-//-). 
    \end{align*}

    Επομένως, για να έχουμε κάθε χρονική στιγμή την τρέχουσα τιμή του πίνακα $\Phi(t)$, στην επίλυση του συστήματος των διαφορικών με \textit{ode45}
    συμπεριλαμβάνουμε και τις παραπάνω τρεις. 
\end{examplebox}

\newpage

\subsubsection{Προσομοίωση στο MATLAB}
TODO: \\
- Πως μοντελοποιώ το ω \\
- Κάνε ένα σχόλιο για ευστάθεια \\
\subsubsection{Αποτελέσματα MATLAB και Συμπεράσματα}
TODO: \\
- Βάλε πλοτς και πες συμπεράσματα
- πως επηρεάζει το μπαρ-ω την σύγκληση (την κάνει χειρότερη!!)\\



\newpage

\section{Θέμα 2}

Στόχος του θέματος αυτού είναι η μελέτη της \textit{διαδικασίας επιλογής και αξιολόγησης} μοντέλου 
για την προσέγγιση αγνώστου μη-γραμμικού δυναμικού συστήματος της μορφής:
\begin{equation}\label{t2:sys_form}
    \dot x (t) = f(x(t), u(t), \theta), \quad f: \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}, 
\end{equation}
με $u(t) \in \mathbb{R}$ και $x(t)\in \mathbb{R}$ να είναι μετρήσιμα και να αποτελούν την είσοδο και την έξοδο του συστήματος, αντίστοιχα, ενώ
$\theta = [\theta_1, \theta_2]^{\top} \in \mathbb{R}^2$ είναι ένα σταθερό διάνυσμα παραμέτρων. 

Για το πραγματικό μη γραμμικό σύστημα που περιγράφεται από την \eqref{t2:sys_form} ισχύει:
\begin{equation}\label{t2:f_true}
    f(x, u, \theta) = - x^3 + \theta_1 \tanh(x) + \theta_2 \frac{1}{1 + x^2} + u, 
\end{equation}
όπου $\theta_1, \theta_2 \in [0.5, 2]$ και $u(t)$ είναι δικής μας επιλογής. 


\newpage




\end{document}
